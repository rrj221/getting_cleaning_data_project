install.packages("swirl")
swirl()
library(swirl)
library(swirl)
install.packages("swirl")
library(swirl)
install.packages("swirl")
install.packages("swirl")
install.packages("swirl")
install.packages("rjava")
yes
install.packages("rJava")
install.packages("xlsx")
library(xlsx)
install.packages("RMySQL", type = "source")
library(RMySQL)
uscsDb <- dbConnect(MySQL(), user="genome", host="genome-mysql.cse.ucsc.edu")
result <- dbGetQuery(uscsDb,"show databases;"); dbDisconnect(uscsDb)
result
hg19 <- dbConnect(MySQL(), user="genome", db="hg19", host="genome-mysql.cse.ucsc.edu")
allTables <- dbListTables(hg19)
alTables
allTables
head(allTables)
dbListFields(hg19, "affyU133Plus2")
dbGetQuery(hg19, "select count(*) from affyU133Plus2")
dbGetQuery(hg19, "select bin from affyU133Plus2")
dbGetQuery(hg19, "select count(*) from affyU133Plus2")
affyData <- dbReadTable(hg19, "affyU133Plus2")
head(affyData)
query <- dbSendQuery(hg19, "select * from affyU133Plus2" where misMatches between 1 and 3")
query <- dbSendQuery(hg19, "select * from affyU133Plus2 where misMatches between 1 and 3")
affyMis <- fetch(query); quantile(affyMis$misMatches)
affyMisSmall <- fetch(query, n=10); dbClearResult(query)
dim(affyMisSmall)
affyMisSmall
dbDisconnect(hg19)
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
N
library(rhdf5)
created = h5createFile("example.h5")
created
created = h5createGroup("example.h5", "foo")
created = h5createGroup("example.h5", "baa")
created = h5createGroup("example.h5", "foo/foobaa")
h5ls("example.h5")
con = url("http://scholar.google.com/citations?user=HI-I6C0AAAJ&hl=en")
htmlCode = readLines(con)
close(con)
htmlCode
head(htmlCode)
url<- "http://scholar.google.com/citations?user=HI-I6C0AAAJ&hl=en"
library(XML)
html <- htmlTreeParse(url, useInternalNodes = TRUE)
library(httr)
html2 = GET("cnn.com")
content2 = content(html2, as="text")
parsedHmtl = htmlParse(content2, asText=TRUE)
xpathSApply(parsedHmtl, "//title", xmlValue)
google = handle("http://google.com")
pg1 = GET(handle=google, path="/")
pg2 = GET(handle=google, path="search")
myapp = oauth_app("twitter", key = "mfPgl2zeDBVNUYFWbwpoFv4T9", secret = "mdpfKV11FAnZPhwJz2z0QQXqThTGd7zgBUZzQ4skZRgDAEjnto")
sig = sign_oauth1.0(myapp, token = "57149153-Jq3ShuGfzfBlGEILfy7oXHgginj29yCvLtgzVaoSu", token_secret = "GrPZGIp8e5Jya08fdudovsnOdqsnzqdY0G7zzINg4pra0
")
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)
json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
library(jsonlite)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[1, 1:4]
json2
myapp = oauth_app("twitter", key = "ft2cfdIxprxsDS4Y4dDME6ZSu
", secret = "5uy5i9JTlbKTXe67XlR0VyrjFHi0IwqZREx0LCnW0rKgJP7p7C
")
sig = sign_oauth1.0(myapp, token = "57149153-XwPGLmx6sDKvqwDQ0mgjCAMencW1wtZYYFEjiXyuy
", token_secret = "vLDyTI2dNdqMgD2rg85POwmnNlQKU4AVxVEnH22pFTKnh
")
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)
json1 = content(homeTL)
json1
json2 = jsonlite::fromJSON(toJSON(json1))
json2
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)
homeTL
sig = sign_oauth1.0(myapp, token = "57149153-XwPGLmx6sDKvqwDQ0mgjCAMencW1wtZYYFEjiXyuy", token_secret = "vLDyTI2dNdqMgD2rg85POwmnNlQKU4AVxVEnH22pFTKnh")
myapp = oauth_app("twitter", key = "ft2cfdIxprxsDS4Y4dDME6ZSu", secret = "5uy5i9JTlbKTXe67XlR0VyrjFHi0IwqZREx0LCnW0rKgJP7p7C")
sig = sign_oauth1.0(myapp, token = "57149153-XwPGLmx6sDKvqwDQ0mgjCAMencW1wtZYYFEjiXyuy", token_secret = "vLDyTI2dNdqMgD2rg85POwmnNlQKU4AVxVEnH22pFTKnh")
homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)
homeTL
json1 = content(homeTL)
json2 = jsonlite::fromJSON(toJSON(json1))
json2[1, 1:4]
library(httpuv)
install.packages("httpuv")
library(httpuv)
install.packages("yaml")
install.packages("httpuv")
remove.packages("httpuv")
install.packages("httpuv")
library(httpuv)
remove.packages("httpv")
remove.packages("httpuv")
install.packages("httpuv")
library(httpuv)
install.packages("httpuv")
remove.packages("httpuv")
library(httpuv)
install.packages("httpuv")
library(httpuv)
install.packages("rccp")
.libPaths()
setwd("getting_and_cleaning_data")
getwd()
dir()
setwd("week4")
getwd()
dir()
dir.create("quiz")
setwd("quiz")
dir.create("data")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv", "data/q1.csv")
q1 <- read.csv("data.q1.csv")
q1 <- read.csv("data/q1.csv")
head(q1)
strsplit(q1, "wgtp")
sapply(x, function(x) {strsplit(x, "wgtp")})
strsplit(names(q1), "wgtp")
strsplit(names(q1), "wgtp")[[123]]
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv", "data/q2.csv")
q2 <- read.csv("data/q2.csv")
head(q2)
q2 <- read.csv("data/q2.csv", skip = 4)
head(q2)
names(q2) <- c("Country", "Ranking", "Blank", "Country_Long", "GDP", "1", "2", "3", "4")
head(q2)
library(dplyr)
q2 <- select(q2, Country, Ranking, Country_Long, GDP)
head(q2)
tail(q2)
tail(q2, 50)
tail(q2, 100)
head(q2, 20)
q22 <- q2[1:190,]
tail(q22)
sapply(q22$GDP, function(x){gsub(",", "", x)})
gdps <- sapply(q22$GDP, function(x){gsub(",", "", x)})
gpds[1,]
gdps[1,]
gdps
gdps[1]
gdps <- sapply(gdps, function(x){gsub(" ", "", x)})
gdps
gdps[2]
gdps <- sapply(q22$GDP, function(x){gsub(",", "", x)})
gdps
sapply(gdps, function(x){gsub(" ", "", x)})
q22$GDP <- as.numeric(as.character(q22$GDP))
q22$GDP
q22 <- q2[1:190,]
q22$GDP
q22$GDP[1][1:4]
q22$GDP[1]
typeof(q22$GDP[1])
q22$GDP[1] + g22$GDP[2]
q22$GDP[1] + q22$GDP[2]
q2 <- read.csv("data/q2.csv", skip = 4, stringsAsFactors = F)
q23 <- q2[1:190,]
head(q23)
names(q2) <- c("Country", "Ranking", "Blank", "Country_Long", "GDP", "1", "2", "3", "4")
names(q23) <- c("Country", "Ranking", "Blank", "Country_Long", "GDP", "1", "2", "3", "4")
q23 <- select(q23, Country, Ranking, Country_Long, GDP)
head(q23)
q23$GDP[1]
gdp <- q23$GDP
gdp
gsub(" ", "", gdp)
gdp <- gsub(" ", "", gdp)
gdp <- gsub(",", "", gdp)
gdp
gdp[1] + gdp[2]
gdp <- as.numeric(gdp)
gdp[1]
mean(gdp)
q23
head(q23)
grep("*United", q23$Country_Long)
grep("^United", q23$Country_Long)
table(grep("^United", q23$Country_Long))
grep("^United", q23$Country_Long)
grep("^United", q23$Country_Long, names=TRUE)
grep("^United", q23$Country_Long, value = T)
q4 <- q23
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv", "data/q4_2.csv")
q4ed <- read.csv("data/q4_2.csv", stringsAsFactors = F)
View(q4ed)
q4both <- merge(q4, q4ed, by.x = "Country", by.y = "CountryCode")
View(q4both)
notes <- q4both$Special.Notes
notes
grep("Fiscal year end", notes)
yearEnds <- grep("Fiscal year end", notes, value = T)
yearEnds
library(lubridate)
library(stringr)
substr(yearEnds[1], grep("Fiscal year end: "))
substr(yearEnds[1], grep("Fiscal year end: ",15))
one <- yearEnds[1]
one
substr(one, nchar("Fiscal year end: ", 20))
substr(one, nchar("Fiscal year end: "), 20))
substr(one, nchar("Fiscal year end: "), 20)
substr(one, nchar("Fiscal year end: "), 10)
substr(one, nchar("Fiscal year end: "), 50)
substr(one, nchar("Fiscal year end: "))
substr(one, nchar("Fiscal year end: "), stop = false)
substr(one, nchar("Fiscal year end: "), nchar(one))
substr(one, nchar("Fiscal year end: ") + 1, nchar(one))
one <- substr(one, nchar("Fiscal year end: ") + 1, nchar(one))
grep(";", one)
str_locate(";", one)
one
str_locate(pattern = ";", one)
str_locate(pattern = ";", one)$start
str_locate(pattern = ";", one)[1]
sapply(yearEnds, function (x) {substring(x, nchar(Fiscal year end: ") + 1), str_locate(pattern = ";", x)})
sapply(yearEnds, function (x) {substring(x, nchar(Fiscal year end: ") +1, str_locate(pattern = ";", x)})
sapply(yearEnds, function (x) {substring(x, nchar(Fiscal year end: ") +1, str_locate(pattern = ";", x))})
sapply(yearEnds, function (x) {substring(x, nchar(Fiscal year end: ") +1, str_locate(pattern = ";", x)[1])})
sapply(yearEnds, function (x) {substring(x, nchar(Fiscal year end: ") +1, str_locate(pattern = ";", x)[1]})
sapply(yearEnds, function (x) {substring(x, nchar(Fiscal year end: ") +1, str_locate(pattern = ";", x)[1]}))
sapply(yearEnds, function (x) {substring(x, nchar("Fiscal year end: ") +1, str_locate(pattern = ";", x)[1]})
sapply(yearEnds, function (x) {substring(x, nchar("Fiscal year end: ") +1, str_locate(pattern = ";", x)[1])})
sapply(yearEnds, function(x) {
substring(x, nchar("Fiscal year end: ") + 1),
str_locate(pattern = ";", x)[1])
})
sapply(yearEnds, function(x) {
substring(x, nchar("Fiscal year end: ") + 1,
str_locate(pattern = ";", x)[1])
})
dates <- sapply(yearEnds, function(x) {
substring(x, nchar("Fiscal year end: ") + 1,
str_locate(pattern = ";", x)[1] -1)
})
dates[1]
sapply(dates, function(x){x})
sapply(dates, function(x){as.character(x)})
unlist(dates)
dates
dates <- unlist(dates)
dates
dates[1]
names(dates)
dates <- unlist(dates, use.names = F)
dates
dates <- unlist(dates, use.names = FALSE)
dates
yearEnds
one
date(one)
dates <- sapply(yearEnds, function(x) {
str_locate(pattern = ":") + 2,
str_locate(pattern = ";", x)[1] -1)
})
dates <- sapply(yearEnds, function(x) {
str_locate(pattern = ":", x) + 2,
str_locate(pattern = ";", x)[1] -1)
})
dates <- sapply(yearEnds, function(x) {
substr(
str_locate(pattern = ":", x) + 2,
str_locate(pattern = ";", x)[1] -1)
)
})
dates <- sapply(yearEnds, function(x) {
substr(
x,
str_locate(pattern = ":", x) + 2,
str_locate(pattern = ";", x)[1] -1
)
})
dates
unlist(dates, use.names = F)
sapply(dates, month)
sapply(dates, function(x), month(x))
grep("June", dates)
length(grep("June", dates))
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
sampleTimes
year(sampleTimes[1])
sampleTimes[year(sampleTimes) == 2012]
length(sampleTimes[year(sampleTimes) == 2012])
length(sampleTimes[day(sampleTimes) == "Monday"])
day(sampleTimes[1])
length(sampleTimes[day(sampleTimes) == 1])
day("Monday")
day("2018-04-30")
weekday("2018-04-30")
wday("2018-04-30")
length(sampleTimes[wday(sampleTimes) == 2])
wday("2018-04-29")
length(sampleTimes[wday(sampleTimes) == 2] | sampleTimes[year(sampleTimes) == 2012])
length(sampleTimes[wday(sampleTimes) == 2] & sampleTimes[year(sampleTimes) == 2012])
length(sampleTimes[wday(sampleTimes) == 2] && sampleTimes[year(sampleTimes) == 2012])
length(sampleTimes[wday(sampleTimes) == 2 & year(sampleTimes == 2012)])
length(sampleTimes[wday(sampleTimes) == 2 && year(sampleTimes == 2012)])
2012 <- sampleTimes[year(sampleTimes) == 2012]
twelve <- sampleTimes[year(sampleTimes) == 2012]
length(sampleTimes[wday(twelve) == 2])
length(twelve[wday(twelve) == 2])
setwd("../hw")
xtest <- read.table("data/test/X_test", header = TRUE)
ls("data/test")
ls("data")
dir("data/test")
xtest <- read.table("data/test/X_test.txt", header = TRUE)
dim(xteset)
dim(xtest)
neames(xtest)
names(xtest)
head(xtest)
head(xtest[,1])
xtest[,1]
dim(xtest)
xtest <- read.table("data/test/X_test.txt", header = FALSE)
head(xtest[,1])
dim(xtest)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip", "data")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip", "data/file.txt")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip", "data/file.zip")
zip.file.extract("data/file.zip", "file.zip")
zip.unpack("data/file.zip", "data/zipped")
install.packages("unzip")
unzip("data/file.zip", "data")
unzip("data/file.zip")
source("run_analysis.R")
source("run_analysis")
dir()
dir()[2]
source(dir()[2])
source(dir()[2])
source(dir()[2])
head(xtest[,1:5])
dim(xtest)
dim(features)
head(features[,5])
head(features[,1:5])
head(features)
source(dir()[2])
source(dir()[2])
head(features)
source(dir()[2])
head(features)
names(xtest) <- features[,2]
head(xtest, 1:10)
head(xtest[,1:10])
tail(xtest[,1:10])
tail(xtest[,550:])
tail(xtest[,550:561])
unique(ytrain)
source('C:/Users/rrj22/OneDrive/Desktop/data_science/technical_track/r_working_directory/getting_and_cleaning_data/week4/hw/run_analysis.R')
source('C:/Users/rrj22/OneDrive/Desktop/data_science/technical_track/r_working_directory/getting_and_cleaning_data/week4/hw/run_analysis.R')
source('C:/Users/rrj22/OneDrive/Desktop/data_science/technical_track/r_working_directory/getting_and_cleaning_data/week4/hw/run_analysis.R')
source('C:/Users/rrj22/OneDrive/Desktop/data_science/technical_track/r_working_directory/getting_and_cleaning_data/week4/hw/run_analysis.R')
head(testData[,1:6])
head(features)
features[,2]
head(testData[,1:6])
dim(testData)
c("subject", "act", features[,2])
features[,2]
typeof(features[,2])
typeof(as.character(features[,2])
)
c("subject", "act", as.character(features[,2]))
dim(xtest)
dim(ytest)
dim(subjectTest)
source('C:/Users/rrj22/OneDrive/Desktop/data_science/technical_track/r_working_directory/getting_and_cleaning_data/week4/hw/run_analysis.R')
head(testData[,1:6])
unique(testData$subject)
unique(trainData$subject)
length(unique(trainData$subject))
21/30
length(trainData$subject)
length(testData[,1])
2947+7352
2947/10299
combined <- rbind(testData, trainData)
combined
head(combined[,1:5])
unique(combined$subject)
length(unique(combined$subject))
head(combined[,1:6])
head(features)
grep("mean" | "std, features[,2]
)
)
)
))
grep("mean" | "std", features[,2])
grep("mean|std", features[,2])
grep("mean|std", features[,2], value = T)
library(dplyr)
names <- grep("mean|std", features[,2], value = T)
rm(names)
names
names <- grep("mean|std", features[,2], value = T)
names
names <- grep("mean|std", features[,2])
names <- grep("mean|std", features[,2])
names
names +2
select(combinedData, c(1, 2, names+2))
select(combined, c(1, 2, names+2))
combined
select(combined, names)
select(combined, 3)
head(combined[names][,5]
)
head(combined[,names][,5])
head(combined[,names])
head(combined[,names]+2)
names(head(combined[,names]+2))
names
names <- grep("mean|std", features[,2])
names
names <- grep("mean|std", features[,2])+2
names
names <- c(1:2, grep("mean|std", features[,2])+2)
names
head(combined[,names][,1:5])
meanStdData <- combined[,names]
names(meanStdData)
length(names(meanStdData))
head(combined[,names][,1:5])
library(plyr)
activityLabels
merge(meanStdData$activity, activityLabels, by.x = 1, by.y = 1)
merged <- merge(meanStdData$activity, activityLabels, by.x = 1, by.y = 1)
merged[5250:5260]
merged[5250:5260,]
source('C:/Users/rrj22/OneDrive/Desktop/data_science/technical_track/r_working_directory/getting_and_cleaning_data/week4/hw/run_analysis.R')
head(meanStdData[,1:7])
names(meanStdData)
names(meanStdData[-1, -2])
names(meanStdData[-1:2])
names(meanStdData[-(1:2)])
group_by(meanStdData, subject) %>% summarize(mean = mean(fbodyAcc-mean()-X))
group_by(meanStdData, subject) %>% summarize(mean = mean("fbodyAcc-mean()-X"))
meanStdData[2,3]
meanStdData[2,3]+1
library(reshape2)
nlength(meanStdData(names))
length(meanStdData(names))
length(names(meanStdData))
dcast(meanStdData, subject ~ activity, mean())
dcast(meanStdData, subject ~ activity, mean
)
dcast(meanStdData, subject + activity ~ 3:81, mean)
dcast(meanStdData, subject + activity ~ meanStdData[3:81], mean)
dcast(meanStdData, subject + activity ~ meanStdData[,3:81], mean)
dcast(meanStdData, subject + activity ~ names(meanStdData)[3:81], mean)
head(dcast(meanStdData, subject + activity ~ names(meanStdData)[3:81], mean)[,1:5])
head(dcast(meanStdData, subject + activity ~ names(meanStdData)[3:81], mean)[,1:5], 10)
write.table(meanStdData, "data/daters.csv", sep = ",")
write.table(combinedData, "data/daters2.csv", sep = ",")
meanStdData <- combinedData[,names]
merge(meanStdData$activity, activityLabels, by.x = 1, by.y = 1)[,2]
unique(merge(meanStdData$activity, activityLabels, by.x = 1, by.y = 1)[,2])
View(merge(meanStdData$activity, activityLabels, by.x = 1, by.y = 1)[,2])
View(merge(meanStdData$activity, activityLabels, by.x = 1, by.y = 1))
meanStdData$activity
View(join(meanStdData$activity, activityLabels, by = 1)
)
View(join(meanStdData$activity, activityLabels))
head(activityLabels)
names(activityLabels) <- c("activity", "activitylong")
join(meanStdData, activityLabels, activity)
join(meanStdData, activityLabels, by = "activity")
join(meanStdData$activity, activityLabels, by = "activity")
source('C:/Users/rrj22/OneDrive/Desktop/data_science/technical_track/r_working_directory/getting_and_cleaning_data/week4/hw/run_analysis.R')
source('C:/Users/rrj22/OneDrive/Desktop/data_science/technical_track/r_working_directory/getting_and_cleaning_data/week4/hw/run_analysis.R')
source('C:/Users/rrj22/OneDrive/Desktop/data_science/technical_track/r_working_directory/getting_and_cleaning_data/week4/hw/run_analysis.R')
head(meanStdData[,1:5])
meanStdData[95:100,1:5]
meanStdData[159:160,1:5]
meanStdData[158:160,1:5]
head(dcast(meanStdData, subject + activity ~ names(meanStdData)[3:81], mean)[,1:5], 10)
names(meanStdData)
head(dcast(meanStdData, subject + activity ~ names(meanStdData)[3:81], mean)[,1:5], 10)
write.table(meanStdData, "data/daters3.csv", sep = ",")
head(dcast(meanStdData, subject + activity, mean)[,1:5], 10)
head(dcast(meanStdData, subject + activity ~ meanStdData, mean)[,1:5], 10)
head(dcast(meanStdData, subject + activity ~ "tBodyAcc-mean()-X", mean)[,1:5], 10)
head(dcast(meanStdData, subject + activity ~ names(meanStdData)[1:81], mean)[,1:5], 10)
head(dcast(meanStdData, subject + activity ~ names(meanStdData)[2:81], mean)[,1:5], 10)
head(dcast(meanStdData, subject + activity ~ names(meanStdData)[3:81], mean)[,1:5], 10)
melt <- melt(meanStdData, id = c("subject", "activity"), measure.vars = names(meanStdData)[3:31])
melt
dcast(melt, subject + activity ~ variable)
dcast(melt, subject + activity ~ variable, mean)
source('C:/Users/rrj22/OneDrive/Desktop/data_science/technical_track/r_working_directory/getting_and_cleaning_data/week4/hw/run_analysis.R')
write.csv(summary, "data/summary.csv")
head(meanStdData[,1:5])
melt
dcast(melt, subject + activity ~ variable, mean)
